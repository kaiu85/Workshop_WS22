{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kaiu85/Workshop_WS22/blob/main/Session_02_building_models_in_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UXfgc2zh-8D"
      },
      "source": [
        "# 4EU+ Day Two - Session 2 - Building Models\n",
        "**Date:** 13.05.2022\n",
        "\n",
        "By: Koen Frolichs (k.frolichs@gmail.com)\n",
        "\n",
        "_From Mathematics to code_: In this session we will build Rescorla-Wagner Reinforcement Learning  models in Python one step at a time. At the end you should feel (somewhat) confident in translating your own ideas for models into code that you can run, simulate and analyse.\n",
        "\n",
        "Stuff we want to do in this session:\n",
        "\n",
        "*   Translate a mathematical formula into functioning code\n",
        "*   Visualize our modelling results\n",
        "\n",
        "## Other Sessions\n",
        "* [Session 01](https://colab.research.google.com/drive/1BDNNJm0Mtl8fBYpQz7hYtXhjqAWls6H4?usp=sharing)\n",
        "* [Session 03](https://colab.research.google.com/drive/1oNtwyj_RFRm2DgetjOuZ3GMt9TQofS5b?usp=sharing)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TM5_xHXV3R1l"
      },
      "source": [
        "## Translating formulas into code\n",
        "\n",
        "In the beginning it might be hard to see how a model expressed by a formula can be implemented in code. It might take a bit of adjustment but once you see it it's actually very straightforward."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdPXLusO3uBu"
      },
      "source": [
        "To start with a simple example:\n",
        "\n",
        "The formula $\\sum_{n=1}^{10}n$ which expresses the summation of the numbers 1-10 (e.g., $1+2+3+\\cdots+10$).\n",
        "\n",
        "Can already easily be expressed in code by you!\n",
        "You can write your own loop, use an existing function, or create your own function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0CHCQbKc5Pqj"
      },
      "outputs": [],
      "source": [
        "# Write or use code to sum up the first 100 integers\n",
        "# There's an equation to this: (n*(n+1))/2\n",
        "n = 100\n",
        "ans_one = (n*(n+1))//2 # The double // makes it an integer value (instead of a float)\n",
        "print(\"Answer One:\",ans_one)\n",
        "\n",
        "# you can do it in a loop\n",
        "ans_two = 0\n",
        "for i in range(n+1):\n",
        "  ans_two += i # += is the same as writing: ans_two = ans_two + i\n",
        "print(\"Answer Two:\",ans_two)\n",
        "\n",
        "# This is also a loop but a bit fancier\n",
        "ans_three = sum([i for i in range(n+1)])\n",
        "print(\"Answer Three:\",ans_three)\n",
        "\n",
        "# And probably a lot of other ways to do this!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feAxDkK2Z2xm"
      },
      "source": [
        "## Simple Reinforcement Learning\n",
        "As introduced in the lecture, Rescorla-Wagner (RW) models are simple but powerful models of behavior. That learn through their use of the prediction error (PE). That is, they slowly adjust their expectations based on the PE to match the outcome.\n",
        "\n",
        "## Toy Problems\n",
        "Often when programming we create simple idealized problems to understand what's going on (so called: **toy problems**). Toy problems are great because they are an abstraction of reality, this way we can only focus on the things we find important right now! Moreover, real data is often messy, noisy and inconsistent so if something doesn't you cannot be sure if it's a mistake you made or if it's caused by the data. With toy problems it's **always your mistake** ;).\n",
        "We will use toy problems throughout this notebook.\n",
        "\n",
        "## Classical Conditioning\n",
        "Let's try to model the standard classical conditioning paradigm (dog, bell, and food)\n",
        "\n",
        "Let's assume the dog's prediction for food when hearing a bell can be a value between [0 1], initially it has no expectation so its prediction is 0 (\"I will not get any food\"). The first time the dog receives food it is very surprised (in modelling terms: its **prediction error** is high). But over time, when the bell is continuously paired with food, it will start to expect the food more and more and thus will have a decreasing learning error.\n",
        "\n",
        "In a formula we can express this as follows: \n",
        "\n",
        "The prediction error at time t, where F is the feedback and P the prediction:\n",
        "\n",
        "$PE_t = F_t - P_t$\n",
        "\n",
        "Updating the prediction for the next timepoint (t+1):\n",
        "\n",
        "$P_{t+1}=P_t+α*PE$\n",
        "\n",
        "One thing we haven't mentioned yet is: α. This is also called the **learning rate** and determines how fast the dog learns. We will look at α in a bit more detail later. For now, let's say it is 0.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kfcjx02qgcJn"
      },
      "source": [
        "## One trial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_hjBh1wIgS3M"
      },
      "outputs": [],
      "source": [
        "# General Settings\n",
        "alpha = 0.1\n",
        "\n",
        "feedback = 1\n",
        "first_prediction = 0\n",
        "print(\"The first prediction is: \", first_prediction)\n",
        "\n",
        "PE = feedback - first_prediction\n",
        "print(\"The Prediction Error is: \", PE)\n",
        "\n",
        "next_prediction = first_prediction + (alpha*PE)\n",
        "print(\"\\nThe next prediction is: \", next_prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuGIMIx3hDqO"
      },
      "source": [
        "## Multiple trials\n",
        "One trial doesn't tell us much of course.. So let's *simulate* a couple trials in a row."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "atwmeHwkhB4v",
        "outputId": "bf691024-6f23-4921-96bc-90fccf510728",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0.1, 0.19, 0.271, 0.34390000000000004, 0.40951000000000004, 0.46855900000000006, 0.5217031000000001, 0.5695327900000001, 0.6125795110000001]\n"
          ]
        }
      ],
      "source": [
        "alpha = 0.1\n",
        "trials = 10\n",
        "\n",
        "feedback = 1 # Here we assume the feedback will always be one\n",
        "# Let's create a list of predictions and update it per trial that so we can see it change in time\n",
        "prediction = [0 for _ in range(trials)] # If you don't believe this will create a list with 0's print it!\n",
        "\n",
        "# Because we have a procedure that needs to be repeated multiple times we can use a loop\n",
        "# Fill in the rest of the loop\n",
        "for trial_num in range(trials-1):\n",
        "  # Calculate the PE (during a specific trial number!)\n",
        "  # Hint trial numbers are saved in the trial_num variable\n",
        "  PE = feedback - prediction[trial_num]\n",
        "  # Update the Prediciton for the next trial\n",
        "  prediction[trial_num+1] = prediction[trial_num] + alpha*PE\n",
        "\n",
        "# Print the prediction and see if it increases over time!\n",
        "# You can play around with the parameters to see how they work\n",
        "print(prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vn9nT1M9jk0m"
      },
      "source": [
        "## Plotting your results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJBZTv3WjSuM",
        "outputId": "0877aec2-f2ff-4fa6-a354-f51a37c0ea0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.8)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib) (4.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "# For plotting we will use matplotlib this is not installed on Colab normally\n",
        "# but we can import it with the following command\n",
        "!pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGRSejgSjtMN"
      },
      "outputs": [],
      "source": [
        "# Once installed, we have to import it\n",
        "# We rename it to plt so we don't have to type matplotlib.pyplot every time\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48iGqGU8kQTN",
        "outputId": "225084fb-48f5-4428-dfea-b4df05637351",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Rescorla-Wagner model')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# If both the installation and importing functioned\n",
        "# You can plot your results from prediction by running the following code\n",
        "\n",
        "plt.plot(prediction) # Plotting the predictions\n",
        "\n",
        "# Adding some labels to the axes and a title!\n",
        "plt.xlabel('Trials')\n",
        "plt.ylabel('Prediction')\n",
        "plt.title('Rescorla-Wagner model')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dIPnxSal0Sh"
      },
      "source": [
        "## Congratulations!\n",
        "### You have succesfully modelled and visualized learning!\n",
        "\n",
        "Let's play around with this simple model a little more before we move on to a little more complex models.\n",
        "\n",
        "## Learning Rate: α\n",
        "As stated above, α (learning rate) determines how fast an agent learns. Let's try to simulate and plot four different learning rates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eAQgA-WJnH_l"
      },
      "outputs": [],
      "source": [
        "alpha_nums = [0, .25, .5, 1]\n",
        "trials     = 10\n",
        "feedback   = 1\n",
        "idx = 1 # Will be used for plotting\n",
        "\n",
        "for alpha in alpha_nums:\n",
        "  prediction = [0 for _ in range(trials)]\n",
        "  # This will loop over four alpha values\n",
        "  # You can copy or rewrite your original code here to simulate the learning four times\n",
        "  #---------------------------------------------------------------------------#\n",
        "  for trial_num in range(trials-1):\n",
        "    # Calculate the PE (during a specific trial number!)\n",
        "    # Hint trial numbers are saved in the trial_num variable\n",
        "    PE = feedback - prediction[trial_num]\n",
        "    # Update the Prediciton for the next trial\n",
        "    prediction[trial_num+1] = prediction[trial_num] + alpha*PE\n",
        "  #---------------------------------------------------------------------------#\n",
        "  \n",
        "  # This will plot the results in a 2x2 matrix\n",
        "  plt.subplot(2,2,idx)\n",
        "  plt.plot(prediction)\n",
        "  plt.ylim([0,1])\n",
        "  plt.title('Learning rate: '+str(alpha))\n",
        "  plt.xlabel('Trials')\n",
        "  plt.ylabel('Prediction')\n",
        "  plt.tight_layout()\n",
        "  idx += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwuU30jGq5Za"
      },
      "source": [
        "## Noisy data environment\n",
        "Our data is not always this clean, let's use a bit of randomness!\n",
        "\n",
        "Let's assume the dog will only be rewarded 70% of the time\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59AoeYvHr600"
      },
      "outputs": [],
      "source": [
        "# This imports a module that can create (pseudo) random numbers\n",
        "from random import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Os734AkOrqDc"
      },
      "outputs": [],
      "source": [
        "# Play around with these parameters a little bit to see what happens\n",
        "trials = 10\n",
        "reward_probability = .7\n",
        "alpha = 0.4\n",
        "\n",
        "# First we need to create a list with rewards\n",
        "feedback = [] # We will create an empty list and fill it with numbers\n",
        "\n",
        "# We will use the function random()\n",
        "# This will generate a random value between 0 and 1\n",
        "for t in range(trials):\n",
        "  if random() <= reward_probability:\n",
        "    # If the value is equal or smaller than 0.7 this is a reward trial\n",
        "    feedback.append(1)\n",
        "  else:\n",
        "    # If it is > .7 it will be a no-reward trial\n",
        "    feedback.append(0)\n",
        "print('The feedback is:\\n', feedback)\n",
        "\n",
        "# The model\n",
        "prediction = [0 for _ in range(trials)]\n",
        "for trial_num in range(trials-1):\n",
        "  PE = feedback[trial_num] - prediction[trial_num]\n",
        "  prediction[trial_num+1] = prediction[trial_num] + (alpha*PE)\n",
        "\n",
        "# Plotting Prediction and feedback\n",
        "plt.plot(prediction)\n",
        "plt.plot(feedback,'o')\n",
        "plt.figlegend(['Prediction','Feedback'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fJSe_Hsv1TD"
      },
      "source": [
        "# Time to create more complex models!\n",
        "\n",
        "These very simple RW models are fun and can explain some interesting data but we would like to expand them a little more!\n",
        "\n",
        "First we will switch from virtual dogs to virtual humans. Because one of the things we are interested in in [our lab](http://www.dnhi-lab.org/) is how humans learn about others' personalities. We can use the same RW models but will add some complexities to make them more interesting!\n",
        "\n",
        "## Personality Learning\n",
        "It is intuitively clear that when learning about others you use more knowledge than just the simple updating from the RW model. You have, for instance, preconceptions about people. That is, you expect certain people to behave in certain ways e.g., students might be more outgoing, scientists quiet and shy, fashion models arrogant and vain etc. etc.. This is something the Rescorla-Wagner models do not capture, but we can **add** this information to these models.\n",
        "\n",
        "## Reference Points\n",
        "We named these preconceived notions about others' personality **Reference Points (RPs)** because we assume you use them as a reference during learning.\n",
        "\n",
        "## More toy problems\n",
        "*First*, we'll create models that use the RPs next to regular learning and see how this influences model behavior.\n",
        "\n",
        "*Second*, we'll add another group for whom people might have different RPs, and explore how the models behave for these two different groups."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrQsQya57tM0"
      },
      "source": [
        "## Creating models that include the RP\n",
        "But what data/ structure are the models learning?\n",
        "Let's assume for now that, when learning about others' personality, people learn a single summary value for each of the [Big Five](https://en.wikipedia.org/wiki/Big_Five_personality_traits) factors.\n",
        "\n",
        "First we will create some ratings our model can learn on:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nNu7Fdx_nerJ"
      },
      "outputs": [],
      "source": [
        "# Creating a profile\n",
        "# For now, we will just pick an average value for each of the Big-5 factors \n",
        "# and add some noise for variability.\n",
        "# The scale is from 1 (doesn't apply at all) to 8 (does apply very much)\n",
        "trials = 10 # number of trials within a factor\n",
        "big5avg = [2,3,7,5,7]\n",
        "\n",
        "# This creates the trials with ratings and adds some noise\n",
        "ratings = [[i+random() for i in big5avg for _ in range(trials)]][0]\n",
        "# Resets will indicate to the model when a new factor is presented\n",
        "resets = [0 for _ in range(trials)]\n",
        "resets[0] = 1\n",
        "resets = resets*5\n",
        "\n",
        "# Let's plot these ratings to see what we are working with\n",
        "plt.plot(ratings)\n",
        "plt.plot(resets,'*')\n",
        "plt.ylabel('Rating')\n",
        "plt.title('Simulated Self-Ratings')\n",
        "plt.xticks([5,15,25,35,45])\n",
        "ax = plt.gca()\n",
        "ax.set_xticklabels(['Agreeable','Conscientious','Openness','Extraversion','Neuroticism'])\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Oj1SzPGrKFA"
      },
      "source": [
        "Now that we have some simulated self ratings. Let's create a model that can do something with this data.\n",
        "\n",
        "First we will adapt the model we built previously to learn on this data. In order for that to be possible we have to make sure it learns a single value per factor. We will use the **resets** list we created so the model knows when it's learning about a new factor.\n",
        "\n",
        "We can update our previous formula a little bit:\n",
        "\n",
        "Original: $P_{t+1}=P_t+α*PE$\n",
        "\n",
        "Updated : $P_{t+1,F}=P_{t,F}+α*PE$\n",
        "\n",
        "We will also wrap this model in a **function** so we can reuse it later!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9bOy8MEVrJlv"
      },
      "outputs": [],
      "source": [
        "# We initialize the model with def\n",
        "def RW_model(ratings, reset, alpha):\n",
        "  \"\"\" This is a simple Rescorla-Wagner model that takes as input:\n",
        "  ratings, reset (indicates new factor), alpha (learning rate)\"\"\"\n",
        "  num_trials = len(ratings)\n",
        "  # First we initialize a list of predictions at zero\n",
        "  prediction = [0 for _ in range(num_trials+1)]\n",
        "  # Now we loop over the trials and apply the model\n",
        "  for trial_num in range(num_trials-1):\n",
        "    # If it is the start of a new factor we predict the midpoint of the scale\n",
        "    if resets[trial_num] == 1:\n",
        "      prediction[trial_num] = 4.5\n",
        "\n",
        "    # Calculate the PE at a certain trial\n",
        "    PE = ratings[trial_num] - prediction[trial_num]\n",
        "    # Update the next prediction\n",
        "    prediction[trial_num+1] = prediction[trial_num] + (alpha*PE)\n",
        "\n",
        "  # Here we will return the model predictions\n",
        "  return prediction[:-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpK60DhmyAab"
      },
      "source": [
        "## Time to test our model!\n",
        "Play around with the alpha learning rate (third parameter) to see what happens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s9SCs4cKtVhW"
      },
      "outputs": [],
      "source": [
        "# Let's call our model with the parameters and see what happens!\n",
        "prediction = RW_model(ratings, resets, 0.1)\n",
        "\n",
        "# Plotting the results\n",
        "plt.title('RW model learning 5 factors')\n",
        "plt.xlabel('Trials')\n",
        "plt.ylabel('Ratings')\n",
        "plt.tight_layout()\n",
        "plt.plot(ratings)\n",
        "plt.plot(prediction)\n",
        "plt.figlegend(['Ratings','Predictions'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmGG_-Amydf_"
      },
      "source": [
        "# Let's create a more complex model!\n",
        "\n",
        "That is, we will now finally add the Reference Point to the model.\n",
        "\n",
        "## How will we represent the reference point (RP)?\n",
        "The RP is *just* a list of \"expected\" ratings. In real data these will be averages of self-ratings, in this notebook we will simulate them.\n",
        "\n",
        "## But how will the models use the RP?\n",
        "The model will combine the simple RW model and the RP to learn. For the model to use both RPs and RW we will need to add a second parameter (γ), that determines how much of the RW and how much of the RP it will use.\n",
        "\n",
        "This is difficult to express in words so let's use a formula:\n",
        "\n",
        "$P_{t+1,F}=γ*RP+(1-γ)*(P_{t,F}+α*PE)$\n",
        "\n",
        "That looks like a lot! But remember this was our old formula:\n",
        "\n",
        "$P_{t+1,F}=P_{t,F}+α*PE$\n",
        "\n",
        "So al that has been added is this part:\n",
        "\n",
        "$γ*RP+(1-γ)*$\n",
        "\n",
        "Let's add this in a new model. First we will create a list with RPs, for now we will use the values we used to create the ratings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cqI647SCvT6-"
      },
      "outputs": [],
      "source": [
        "# Creating a list with RP's\n",
        "trials = 10\n",
        "big5avg = [2,3,7,5,7]\n",
        "\n",
        "# This will create a list with repeated items from the variable big5avg\n",
        "rp = [[i for i in big5avg for _ in range(trials)]][0]\n",
        "print(rp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4101s72o6LVN"
      },
      "source": [
        "Now we can create a model that takes as input the **ratings, reset, alpha, RPs, and gamma**!\n",
        "\n",
        "We can copy a lot from the initial function and just add the RP part"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eMnOsZvm6K2W"
      },
      "outputs": [],
      "source": [
        "def RW_RP_model(ratings, reset, alpha, rp, gamma):\n",
        "  \"\"\" This is a combined Rescorla-Wagner and RP model that takes as input:\n",
        "  ratings, reset (indicates new factor), alpha (learning rate),\n",
        "  RP (list of reference points), and gamma (weighting variable)\"\"\"\n",
        "  num_trials = len(ratings)\n",
        "  # First we initialize a list of predictions at zero\n",
        "  prediction = [0 for _ in range(num_trials+1)]\n",
        "  pred_w_RP  = [0 for _ in range(num_trials+1)]\n",
        "  # Now we loop over the trials and apply the model\n",
        "  for trial_num in range(num_trials-1):\n",
        "    # If it is the start of a new factor we predict the midpoint of the scale\n",
        "    if resets[trial_num] == 1:\n",
        "      prediction[trial_num] = 4.5\n",
        "\n",
        "    # Calculate the PE at a certain trial\n",
        "    PE = ratings[trial_num] - prediction[trial_num]\n",
        "    # Update the next prediction\n",
        "    prediction[trial_num+1] = prediction[trial_num] + (alpha*PE)\n",
        "    \n",
        "    # Here we add the RP part\n",
        "    pred_w_RP[trial_num] = gamma * rp[trial_num] + ((1-gamma)*prediction[trial_num])\n",
        "\n",
        "  return pred_w_RP[:-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWVoK5ZR8XS3"
      },
      "source": [
        "# Plotting the results to see if it's better than the previous model!\n",
        "Play around with the two parameters to see how it changes the models behaviour"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EBDd_Cyb8QKm"
      },
      "outputs": [],
      "source": [
        "prediction = RW_RP_model(ratings, resets, 0.1, rp, 0.5)\n",
        "\n",
        "# Plotting the results\n",
        "plt.title('RW RP model learning 5 factors')\n",
        "plt.xlabel('Trials')\n",
        "plt.ylabel('Ratings')\n",
        "plt.tight_layout()\n",
        "plt.plot(ratings)\n",
        "plt.plot(prediction)\n",
        "plt.figlegend(['Ratings','Predictions'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0WcnaYJ8uAu"
      },
      "source": [
        "We can of course also compare the two models we have now!\n",
        "\n",
        "What happens when you change the gamma parameter (γ) completely to 0 or 1?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZJYL2lO8y2E"
      },
      "outputs": [],
      "source": [
        "prediction = RW_RP_model(ratings, resets, 0.1, rp, .5)\n",
        "pred2 = RW_model(ratings, resets, 0.1)\n",
        "\n",
        "# Plotting the results\n",
        "plt.title('RW RP model learning 5 factors')\n",
        "plt.xlabel('Trials')\n",
        "plt.ylabel('Ratings')\n",
        "plt.tight_layout()\n",
        "plt.plot(ratings)\n",
        "plt.plot(prediction)\n",
        "plt.plot(pred2)\n",
        "plt.figlegend(['Ratings','Predictions RW_RP','Predictions RW'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_Qc8A6p9o8d"
      },
      "source": [
        "# Adding more complexity\n",
        "So now we have a model that can use RP to inform its learning. But we still think that isn't enough! Traits are also related (e.g., if someone is generous they are probably also helpful). That is, knowing about one trait gives you information about other traits. Can we capture this in model?\n",
        "\n",
        "First, can we capture this relatedness in data? Yes, in a correlation!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eLn9DzkCATP6"
      },
      "outputs": [],
      "source": [
        "# We use some functions from numpy from here on. So we will import it\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4J-JsYlChyF"
      },
      "source": [
        "We will use a correlation matrix calculated from over 1 million answers given on an [online IPIP questionnarire](https://ipip.ori.org/new_ipip-50-item-scale.htm). Calculating the correlation takes a bit of time so we have done that already, all you have to do is download the *IPIP_sim.csv* file and upload it in this notebook. You can do this by clicking on the *data* tab on the left side of the screen and then on *upload data*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WV5mYeMwBjZh"
      },
      "outputs": [],
      "source": [
        "# We will use numpy to load the matrix\n",
        "ipip_sim = np.loadtxt('IPIP_sim.csv', delimiter=',')\n",
        "# np.shape(ipip_sim)\n",
        "\n",
        "# Let's visualize it\n",
        "plt.imshow(ipip_sim)\n",
        "plt.colorbar()\n",
        "plt.tight_layout()\n",
        "plt.title('IPIP correlation matrix')\n",
        "plt.xticks(range(5,50,10))\n",
        "plt.yticks(range(5,50,10))\n",
        "ax = plt.gca()\n",
        "ax.set_xticklabels(['Extraversion','Agreeable','Conscientious','Neuroticism','Openness'],Rotation=15)\n",
        "ax.set_yticklabels(['Extraversion','Agreeable','Conscientious','Neuroticism','Openness'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_bysM9dHVzD"
      },
      "source": [
        "## What does this correlation matrix tell us?\n",
        "The green boxes for the factors indicate that items within a factor have higher correlations! Great, this is already what we expected based on the factor model we build. But with these correlations we can look into the data in a more fine-grained way and also model the individual similarities between items! So when learning about one item we can update all other items based on their (cor)relation with the current item!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cclXdCpJJe_C"
      },
      "source": [
        "So now instead of updating *one item* or *one factor* we update **all items** based on the PE from the current item and the other items' correlation to the current item.\n",
        "\n",
        "This is difficult to explain in words so let's try a formula instead:\n",
        "\n",
        "$P_{(t+1,All)} = P_{(t,All)} + \\alpha * PE * SIM$\n",
        "\n",
        "So the Prediction for the next timepoint for **all** items $=$ the current prediction + the $α*PE$ multiplied by their correlation $(SIM)$ to the current item!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5r02MY8YOGQN"
      },
      "outputs": [],
      "source": [
        "# To get the correlations from other items with the current item we can select \n",
        "# either the row or the column (assuming the items are ordered)\n",
        "\n",
        "# This shows the original correlation matrix\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(ipip_sim)\n",
        "plt.colorbar()\n",
        "plt.tight_layout()\n",
        "plt.title('IPIP correlation matrix')\n",
        "plt.xticks(range(5,50,10))\n",
        "plt.yticks(range(5,50,10))\n",
        "ax = plt.gca()\n",
        "ax.set_xticklabels(['Extraversion','Agreeable','Conscientious','Neuroticism','Openness'],Rotation=15)\n",
        "ax.set_yticklabels(['Extraversion','Agreeable','Conscientious','Neuroticism','Openness'])\n",
        "\n",
        "# We can index a row with square brackets [row,column]\n",
        "# If you use the ':' it means the whole column or row\n",
        "plt.subplot(1,2,2)\n",
        "# This will show the rows 1, 11, 21, 31, and 41\n",
        "plt.imshow(ipip_sim[[1,11,21,31,41],:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Qssu2XeKH9S"
      },
      "outputs": [],
      "source": [
        "def RW_SIM_model(ratings, alpha, sim):\n",
        "  \"\"\" This is a combined Rescorla-Wagner and Similarity model that takes as input:\n",
        "  ratings, alpha (learning rate), sim (correlation matrix of items)\"\"\"\n",
        "  num_trials = len(ratings)\n",
        "  # First we initialize a list of predictions at the midpoint!\n",
        "  prediction = [4.5 for _ in range(num_trials)]\n",
        "  # Now we loop over the trials and apply the model\n",
        "  for trial_num in range(num_trials-1):\n",
        "    # Calculate the PE at a certain trial\n",
        "    PE = ratings[trial_num] - prediction[trial_num]\n",
        "    # Update the next prediction\n",
        "    prediction = prediction + (alpha*PE*sim[trial_num,:])\n",
        "  return prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's run this model on our rating data and see how it peforms!"
      ],
      "metadata": {
        "id": "wSpGwONyQ84A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = RW_SIM_model(ratings, 0.1, ipip_sim)\n",
        "\n",
        "# Plotting the results\n",
        "plt.title('RW SIM model learning 5 factors')\n",
        "plt.xlabel('Trials')\n",
        "plt.ylabel('Ratings')\n",
        "plt.tight_layout()\n",
        "plt.plot(ratings)\n",
        "plt.plot(prediction)"
      ],
      "metadata": {
        "id": "L6d6F4IOQGZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Not that great... But that is probably because we simulated ratings.\n",
        "\n",
        "As stated in the beginning: Toy Problems can be very helpful for understanding but sometimes you need *real data*! Tomorrow (session 03) we will have a look at some real data and how to fit these models to them!"
      ],
      "metadata": {
        "id": "GS-lJPiWRBwf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's have one last look at all the models together:"
      ],
      "metadata": {
        "id": "8H4M2HieM1Qt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alpha = 0.3\n",
        "pred1 = RW_model(ratings, resets, alpha)\n",
        "pred2 = RW_RP_model(ratings, resets, alpha, rp, .5)\n",
        "pred3 = RW_SIM_model(ratings, alpha, ipip_sim)\n",
        "\n",
        "# Plotting\n",
        "plt.subplot(2,2,1)\n",
        "plt.plot(ratings)\n",
        "plt.plot(pred1)\n",
        "plt.xlabel('Trial')\n",
        "plt.ylabel('Rating')\n",
        "plt.tight_layout()\n",
        "plt.title('Model 1')\n",
        "\n",
        "plt.subplot(2,2,2)\n",
        "plt.plot(ratings)\n",
        "plt.plot(pred2)\n",
        "plt.xlabel('Trial')\n",
        "plt.ylabel('Rating')\n",
        "plt.tight_layout()\n",
        "plt.title('Model 2')\n",
        "\n",
        "plt.subplot(2,2,3)\n",
        "plt.plot(ratings)\n",
        "plt.plot(pred3)\n",
        "plt.xlabel('Trial')\n",
        "plt.ylabel('Rating')\n",
        "plt.tight_layout()\n",
        "plt.title('Model 3')\n",
        "\n",
        "plt.subplot(2,2,4)\n",
        "plt.plot(ratings)\n",
        "plt.plot(pred1)\n",
        "plt.plot(pred2)\n",
        "plt.plot(pred3)\n",
        "plt.xlabel('Trial')\n",
        "plt.ylabel('Rating')\n",
        "plt.tight_layout()\n",
        "plt.title('All Models together')"
      ],
      "metadata": {
        "id": "dEYF3xwrM4ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Time Leftover\n",
        "If you have some extra time to spare you can try to reconstruct your own models!\n",
        "You can, for instance, create a model that combines the Reference Point and the Similarity into a new model!\n",
        "\n",
        "You can also play around with the figures! Have a look at the [Pyplot documentation](https://matplotlib.org/3.5.0/api/_as_gen/matplotlib.pyplot.html). Can you change some of the colors in the figure or maybe add a legend to a figure that doesn't have one?"
      ],
      "metadata": {
        "id": "oPeg9MclZlEW"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}