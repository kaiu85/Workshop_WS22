{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation der Trainingskurven und der Ergebnisse auf dem Testset\n",
    "\n",
    "Genau wie im Trainings-Notebook importieren wir zunächst einige Bibliotheken, die wir benutzen werden, richten unsere Umgebung ein und wählen die Graphikkarte, die wir für unsere Berechnungen benutzen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Und wir benutzen matplotlib zur graphischen \n",
    "# Darstellung der Lernkurven\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# Diese Funktion liest die Logdateien ein, die wir \n",
    "from RNN_helper_functions import read_log_data\n",
    "\n",
    "# Wir teilen matplotlib mit, dass die Kurven direkt hier ins Notebook gezeichnet werden sollen.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainingskurven\n",
    "Zunächst schauen wir uns die Trainingskurven an. Falls z.B. die Learning-Rate zu groß ist und die Kostenfunktion explodiert, kann man das so sofort erkennen.\n",
    "\n",
    "__Ohne eine Darstellung der Lernkurven, die zeigen, wie sich die Kostenfunktion auf dem Trainings- und Validierungsset während des Trainings entwickelt, sollte man keinem Deep-Learning-Ergebnis trauen.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wir geben den Namen des Netzwerks ein, von dem wir uns die Trainingskurven anschauen wollen.\n",
    "model_name = 'my_own_recipes'\n",
    "\n",
    "# Jetzt lesen wir die Metriken, die wir in der Trainingsschleife nach jeder Epoche gespeichert haben\n",
    "log_file = 'log' + model_name + '.txt'\n",
    "log_data = read_log_data(log_file)\n",
    "\n",
    "# Zuerst zeichnen wir eine Graphik, die die Lernkurven der Kostenfunktion (\"loss\") auf dem Trainings-\n",
    "# und Validierungsset darstellt\n",
    "plt.figure()\n",
    "plt.title('Loss')\n",
    "plt.plot(log_data['epoch'],log_data['train loss'],label=\"train loss\")\n",
    "plt.plot(log_data['epoch'],log_data['validation loss'],label=\"validation loss\")\n",
    "plt.xlabel('Epoche')\n",
    "plt.ylabel('Kostenfunktion')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Man sollte hier sehen, dass die Zielfunktion sowohl auf den Trainingsdaten, als auch auf den Validierungsdaten zun ächstabnimmt.\n",
    "\n",
    "Ab einem gewissen Punkt sollte das Validierungsloss ein Plateau erreichen oder sogar beginnen, wieder anzusteigen.\n",
    "An diesem Punkt beginnt unser Netzwerk, nicht nur die grundlegende Struktur, sondern auch zufällige Rauschartefakte aus den Trainingsdaten zu lernen. Wie gesagt nutzen tiefe neuronale Netze einfach *alles* an Information, was der Trainingsdatensatz anbietet, aus, um die Zielfunktion auf diesem Trainingsdatensatz zu minimieren. Dies führt zum einen dazu, dass die Zielfunktion auf den Trainingsdaten noch weiter sinkt, indem diese im Extremfall einfach auswendig gelernt werden. Da sich solch zufälliges Rauschen in den Trainingsdaten sich jedoch nicht auf neue, ungesehene Daten übertragen lässt, nimmt die Fähigkeit unseres Netzwerks, auch neue, ungesehene Daten sinnvoll zu verarbeiten ab diesem Punkt ab. Man sagt das Netzwerk beginnt mit Overfitting auf den Trainingsdaten (s. Exkurs im Trainingsnotebook). D.h. dass man das Training an dem Punkt, an dem das Validation loss ein Plateau erreicht, beenden sollte.\n",
    "\n",
    "Eine nette Urban Legend zu diesm Thema finden sie hier: https://www.gwern.net/docs/www/neil.fraser.name/e6cd471628867a9b75e6d82e0cc4894856398dd5.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metriken auf dem Testset\n",
    "Als nächstes schauen wir uns den Wert der Zielfunktion auf dem unabhängigen Testset an, das wir bereits im Trainings-Notebook vorbereitet und gespeichert haben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from RNN_helper_functions import load_dataset_info, save_dataset_info\n",
    "\n",
    "dataset_name, indices = load_dataset_info('dataset_' + model_name + '.txt')\n",
    "\n",
    "# Wir geben den Dateinamen des gesamten Datensatzes aus\n",
    "print(dataset_name)\n",
    "# Und die Indices, die Trainings-, Validierungs- und Testdatensatz trennen\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Textgenerierung\n",
    "\n",
    "Wir stellen in der Datei RNN_helper_functions eine Funktion zur Verfügung, um mit wenig Programmieraufwand Text mit ihrem trainierten Modell zu generieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from RNN_helper_functions import sample_from_rnn\n",
    "\n",
    "sample_from_rnn(model_name = model_name, prompt = '''Recipe via''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wie kann ich nun ein RNN einfach in mein eigenes Projekt einbinden?\n",
    "\n",
    "Diese Funktion ist eine von drei Funktionen, die es ihnen ermöglichen soll, in ihren eigenen Projekten relativ einfach RNNs zu Trainieren, deren Training zu überwachen, und mit den trainierten Netzwerken Texte zu generieren. Für Details zur Benutzung betrachten sie bitte das Notebook **03_Easy_to_use_RNNs**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
